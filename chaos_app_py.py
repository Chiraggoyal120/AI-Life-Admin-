# -*- coding: utf-8 -*-
"""chaos_app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g7_0Dw0PWfr10sXbFdXQEo49Pj7r9O4V
"""

# Install all required packages
!pip install gradio openai easyocr pillow python-dotenv aiohttp

# Install OCR support
!apt-get install tesseract-ocr
!pip install pytesseract

import os
# Get your API key from https://openrouter.ai/keys
os.environ['OPENROUTER_API_KEY'] = ''

#!/usr/bin/env python3
"""
AI Life Admin - Creative Gradio Frontend
A beautiful, modern Gradio interface inspired by "Upload Your Chaos" design

Dependencies to install:
pip install gradio openai easyocr pillow python-dotenv aiohttp asyncio-io

For Google Colab, also run:
!apt-get install tesseract-ocr
pip install pytesseract

Usage:
python app.py

Features:
- Beautiful modern UI matching your Loveable design
- File upload with drag & drop
- Text paste area
- Multi-agent AI processing
- Real-time progress indicators
- Animated results display
"""

import gradio as gr
import asyncio
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor
import os
import io
import json
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import base64

# OCR and image processing
import easyocr
from PIL import Image
import pytesseract

# OpenRouter for LLM access
from openai import OpenAI

# Environment variables
from dotenv import load_dotenv
load_dotenv()

class MultiAgentProcessor:
    """Multi-agent system for parallel document processing"""

    def __init__(self, api_key: str, model_name: str = "anthropic/claude-3.5-sonnet"):
        """Initialize the multi-agent processor with OpenRouter API key"""
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=api_key
        )
        self.model_name = model_name
        self.reader = easyocr.Reader(['en'])  # Initialize EasyOCR

    async def extract_text_from_image(self, image) -> str:
        """Extract text from image using OCR"""
        try:
            # Convert PIL Image to bytes for EasyOCR
            img_byte_arr = io.BytesIO()
            image.save(img_byte_arr, format='PNG')
            img_byte_arr = img_byte_arr.getvalue()

            # Use EasyOCR for text extraction
            results = self.reader.readtext(img_byte_arr)
            extracted_text = ' '.join([result[1] for result in results])

            return extracted_text.strip()

        except Exception as e:
            return f"OCR Error: {str(e)}"

    def call_ai_agent(self, agent_prompt: str, text: str) -> str:
        """Single OpenRouter API call for an agent"""
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": agent_prompt},
                    {"role": "user", "content": f"Process this text:\n\n{text}"}
                ],
                max_tokens=500,
                temperature=0.3,
                timeout=30
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"Error: {str(e)}"

    async def run_agents_parallel(self, text: str) -> Dict[str, str]:
        """Run all four agents in parallel using ThreadPoolExecutor"""

        # Define agent prompts
        agent_prompts = {
            "summarizer": """You are a Summarizer Agent. Create a concise, clear summary of the given text in 2-3 sentences.
            Focus on the main points and key information. Use plain language that anyone can understand.""",

            "task_extractor": """You are a Task Extractor Agent. Identify all actionable items, tasks, or to-dos from the text.
            Format as a bulleted list. If no tasks found, return 'No actionable items identified.'""",

            "deadline_extractor": """You are a Deadline Extractor Agent. Find all dates, deadlines, time-sensitive information, or temporal references.
            Include specific dates, relative dates (like 'next week'), and any urgency indicators. Format as a bulleted list.
            If no deadlines found, return 'No deadlines or time-sensitive items identified.'""",

            "entity_extractor": """You are an Entity Extractor Agent. Identify all people, organizations, companies, institutions,
            or other important entities mentioned in the text. Format as a bulleted list with brief context if helpful.
            If no entities found, return 'No specific people or organizations identified.'"""
        }

        # Use ThreadPoolExecutor for parallel execution
        with ThreadPoolExecutor(max_workers=4) as executor:
            # Submit all agent tasks
            future_to_agent = {
                executor.submit(self.call_ai_agent, prompt, text): agent_name
                for agent_name, prompt in agent_prompts.items()
            }

            results = {}

            # Collect results as they complete
            for future in concurrent.futures.as_completed(future_to_agent, timeout=45):
                agent_name = future_to_agent[future]
                try:
                    result = future.result()
                    results[agent_name] = result
                except Exception as e:
                    results[agent_name] = f"Agent failed: {str(e)}"

        return results

# Global processor instance
processor = None

def initialize_processor(api_key: str, model_name: str):
    """Initialize the global processor"""
    global processor
    try:
        processor = MultiAgentProcessor(api_key, model_name)
        return "‚úÖ AI System Ready!"
    except Exception as e:
        return f"‚ùå Initialization failed: {str(e)}"

def process_chaos(file, text_input, api_key, model_choice, progress=gr.Progress()):
    """Main processing function that handles both file and text input with proper priority"""

    if not api_key:
        return "‚ùå Please provide your OpenRouter API key", "", "", "", "", "", gr.update(value="")

    # Initialize processor
    progress(0.1, desc="üöÄ Initializing AI agents...")
    init_result = initialize_processor(api_key, model_choice)
    if "failed" in init_result:
        return init_result, "", "", "", "", "", gr.update(value="")

    # Determine input source and extract text
    text_to_process = ""
    input_source = ""

    # Priority logic: If file is uploaded, use file. Otherwise, use text input.
    if file is not None:
        try:
            progress(0.2, desc="üìÅ Reading your uploaded file...")
            input_source = f"üìÅ **Source**: Uploaded file - {file.name}"

            if file.name.lower().endswith(('.png', '.jpg', '.jpeg')):
                # Handle image files
                progress(0.3, desc="üñºÔ∏è Extracting text from image using OCR...")
                image = Image.open(file.name)
                text_to_process = asyncio.run(processor.extract_text_from_image(image))

                if not text_to_process or len(text_to_process.strip()) < 10:
                    return "‚ùå No meaningful text could be extracted from the image. Please try a clearer image with more text.", "", "", "", "", "", gr.update(value="")

            else:
                # Handle text files
                with open(file.name, 'r', encoding='utf-8') as f:
                    text_to_process = f.read().strip()

        except Exception as e:
            return f"‚ùå File processing error: {str(e)}", "", "", "", "", "", gr.update(value="")

    elif text_input and text_input.strip():
        text_to_process = text_input.strip()
        input_source = "‚úèÔ∏è **Source**: Direct text input"
        progress(0.2, desc="üìù Processing your text input...")

    else:
        return "‚ö†Ô∏è Please upload a file or enter text to process", "", "", "", "", "", gr.update(value="")

    # Validate extracted text
    if len(text_to_process.strip()) < 10:
        return "‚ö†Ô∏è Text is too short for meaningful analysis. Please provide more content.", "", "", "", "", "", gr.update(value="")

    # Show extracted text preview with source information
    text_preview = f"""{input_source}

üìÑ **Extracted Text Preview:**
{text_to_process[:300]}{'...' if len(text_to_process) > 300 else ''}

üìä **Text Length**: {len(text_to_process)} characters"""

    # Run multi-agent processing
    progress(0.4, desc="ü§ñ Running AI agents in parallel...")

    try:
        start_time = datetime.now()
        results = asyncio.run(processor.run_agents_parallel(text_to_process))
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()

        progress(0.8, desc="‚ú® Formatting results...")

        # Format individual results
        summary = f"## üìù Summary\n{results.get('summarizer', 'Summary not available')}"

        tasks = f"## ‚úÖ Action Items\n{results.get('task_extractor', 'No tasks identified')}"

        deadlines = f"## ‚è∞ Deadlines & Time-Sensitive Items\n{results.get('deadline_extractor', 'No deadlines identified')}"

        entities = f"## üë• People & Organizations\n{results.get('entity_extractor', 'No entities identified')}"

        # Create formatted combined output
        formatted_output = f"""# üéØ AI Analysis Results
*Processing completed in {processing_time:.2f} seconds*

{summary}

{tasks}

{deadlines}

{entities}

---
*Powered by Multi-Agent AI System*
"""

        progress(1.0, desc="üéâ Analysis complete!")

        # Clear text input if file was processed to avoid confusion
        text_clear_update = gr.update(value="") if file is not None else gr.update()

        return (
            f"üéâ **Analysis Complete!** Processed in {processing_time:.2f} seconds",
            text_preview,
            summary,
            tasks,
            deadlines,
            entities,
            formatted_output,
            text_clear_update
        )

    except Exception as e:
        return f"‚ùå Processing failed: {str(e)}", "", "", "", "", "", gr.update(value="")

# Custom CSS for beautiful styling
custom_css = """
/* Main container styling */
.gradio-container {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
}

/* Header styling */
.header {
    text-align: center;
    padding: 2rem;
    background: rgba(255, 255, 255, 0.1);
    backdrop-filter: blur(10px);
    border-radius: 20px;
    margin-bottom: 2rem;
    border: 1px solid rgba(255, 255, 255, 0.2);
}

.header h1 {
    font-size: 3rem;
    font-weight: 700;
    background: linear-gradient(45deg, #667eea, #764ba2);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    margin-bottom: 1rem;
}

.header p {
    font-size: 1.2rem;
    color: rgba(255, 255, 255, 0.8);
    margin-bottom: 0;
}

/* Card styling */
.card {
    background: rgba(255, 255, 255, 0.1);
    backdrop-filter: blur(10px);
    border-radius: 16px;
    border: 1px solid rgba(255, 255, 255, 0.2);
    padding: 1.5rem;
    margin: 1rem 0;
}

/* Button styling */
.btn-primary {
    background: linear-gradient(45deg, #667eea, #764ba2) !important;
    border: none !important;
    border-radius: 25px !important;
    padding: 12px 30px !important;
    font-weight: 600 !important;
    font-size: 1.1rem !important;
    color: white !important;
    transition: all 0.3s ease !important;
}

.btn-primary:hover {
    transform: translateY(-2px) !important;
    box-shadow: 0 10px 25px rgba(102, 126, 234, 0.4) !important;
}

/* File upload area */
.file-upload {
    border: 2px dashed rgba(255, 255, 255, 0.3);
    border-radius: 16px;
    background: rgba(255, 255, 255, 0.05);
    padding: 2rem;
    text-align: center;
    transition: all 0.3s ease;
}

.file-upload:hover {
    border-color: rgba(255, 255, 255, 0.6);
    background: rgba(255, 255, 255, 0.1);
}

/* Results section */
.results {
    background: rgba(255, 255, 255, 0.95);
    color: #333;
    border-radius: 16px;
    padding: 2rem;
    margin: 1rem 0;
    box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
}

/* Progress bar */
.progress-bar {
    background: linear-gradient(45deg, #667eea, #764ba2) !important;
    border-radius: 10px !important;
}

/* Input fields */
.input-field {
    border-radius: 12px !important;
    border: 1px solid rgba(255, 255, 255, 0.3) !important;
    background: rgba(255, 255, 255, 0.1) !important;
    backdrop-filter: blur(10px) !important;
    color: white !important;
}

.input-field::placeholder {
    color: rgba(255, 255, 255, 0.7) !important;
}

/* Footer */
.footer {
    text-align: center;
    padding: 2rem;
    color: rgba(255, 255, 255, 0.6);
    font-size: 0.9rem;
}
"""

# Create the Gradio interface
def create_app():
    """Create the beautiful Gradio app"""

    # Available models
    model_choices = [
        "anthropic/claude-3.5-sonnet",
        "openai/gpt-4o",
        "openai/gpt-4o-mini",
        "anthropic/claude-3-haiku",
        "meta-llama/llama-3.1-70b-instruct",
        "mistralai/mistral-large",
        "google/gemini-pro-1.5"
    ]

    with gr.Blocks(css=custom_css, title="AI Life Admin - Upload Your Chaos", theme=gr.themes.Soft()) as app:

        # Header section
        gr.HTML("""
        <div class="header">
            <h1>ü§ñ Upload Your Chaos</h1>
            <p>Drop any document, image, or paste your unstructured text. Our AI will instantly organize it for you.</p>
        </div>
        """)

        # Configuration section
        with gr.Row():
            with gr.Column(scale=2):
                api_key = gr.Textbox(
                    label="üîë OpenRouter API Key",
                    placeholder="sk-or-v1-your-api-key-here",
                    type="password",
                    info="Get your free API key from https://openrouter.ai/keys"
                )
            with gr.Column(scale=1):
                model_choice = gr.Dropdown(
                    label="üß† AI Model",
                    choices=model_choices,
                    value="anthropic/claude-3.5-sonnet",
                    info="Choose your preferred AI model"
                )

        # Main input section
        with gr.Row(equal_height=True):
            with gr.Column(scale=1):
                gr.HTML("<h3 style='text-align: center; color: white; margin-bottom: 1rem;'>üìÅ Upload Files</h3>")
                file_input = gr.File(
                    label="Drop files here or browse to upload",
                    file_types=[".txt", ".pdf", ".jpg", ".png", ".jpeg"],
                    elem_classes=["file-upload"]
                )
                gr.HTML("<p style='text-align: center; color: rgba(255,255,255,0.7); font-size: 0.9rem;'>Supports .txt, .pdf, .jpg, .png files</p>")

            with gr.Column(scale=1):
                gr.HTML("<h3 style='text-align: center; color: white; margin-bottom: 1rem;'>‚úèÔ∏è Or paste your text</h3>")
                text_input = gr.Textbox(
                    label="Paste your unstructured notes, emails, meeting transcripts...",
                    placeholder="Paste your unstructured notes, emails, meeting transcripts, or any text that needs organizing...",
                    lines=8,
                    max_lines=12,
                    elem_classes=["input-field"]
                )

        # Process button
        with gr.Row():
            with gr.Column():
                process_btn = gr.Button(
                    "üöÄ Process with AI",
                    variant="primary",
                    size="lg",
                    elem_classes=["btn-primary"]
                )

        # Status and preview section
        with gr.Row():
            status_output = gr.Markdown(label="üìä Status", visible=True)

        with gr.Row():
            text_preview = gr.Markdown(label="üìÑ Text Preview", visible=True)

        # Results section with tabs
        with gr.Row():
            with gr.Tabs():
                with gr.TabItem("üéØ Complete Analysis", elem_id="complete-tab"):
                    complete_output = gr.Markdown(label="Complete Analysis")

                with gr.TabItem("üìù Summary", elem_id="summary-tab"):
                    summary_output = gr.Markdown(label="AI Summary")

                with gr.TabItem("‚úÖ Action Items", elem_id="tasks-tab"):
                    tasks_output = gr.Markdown(label="Actionable Tasks")

                with gr.TabItem("‚è∞ Deadlines", elem_id="deadlines-tab"):
                    deadlines_output = gr.Markdown(label="Deadlines & Time-Sensitive Items")

                with gr.TabItem("üë• People & Orgs", elem_id="entities-tab"):
                    entities_output = gr.Markdown(label="People & Organizations")

        # Examples section
        gr.HTML("""
        <div style="margin-top: 3rem; padding: 2rem; background: rgba(255,255,255,0.1); border-radius: 16px; backdrop-filter: blur(10px);">
            <h3 style="color: white; text-align: center; margin-bottom: 1.5rem;">üí° Try These Examples</h3>
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 1rem;">
                <div style="background: rgba(255,255,255,0.1); padding: 1rem; border-radius: 12px;">
                    <h4 style="color: #87CEEB;">üìß Meeting Notes</h4>
                    <p style="color: rgba(255,255,255,0.8); font-size: 0.9rem;">Upload messy meeting transcripts to extract action items and deadlines</p>
                </div>
                <div style="background: rgba(255,255,255,0.1); padding: 1rem; border-radius: 12px;">
                    <h4 style="color: #87CEEB;">üìÑ Document Images</h4>
                    <p style="color: rgba(255,255,255,0.8); font-size: 0.9rem;">Take photos of handwritten notes or printed documents</p>
                </div>
                <div style="background: rgba(255,255,255,0.1); padding: 1rem; border-radius: 12px;">
                    <h4 style="color: #87CEEB;">‚úâÔ∏è Email Threads</h4>
                    <p style="color: rgba(255,255,255,0.8); font-size: 0.9rem;">Paste long email conversations to find key information</p>
                </div>
            </div>
        </div>
        """)

        # Footer
        gr.HTML("""
        <div class="footer">
            <p>ü§ñ Built with ‚ù§Ô∏è for the Darwix AI Hackathon | Powered by Multi-Agent AI System</p>
            <div style="margin-top: 1rem;">
                <span style="margin: 0 1rem;">üß†</span>
                <span style="margin: 0 1rem;">‚ö°</span>
                <span style="margin: 0 1rem;">üöÄ</span>
            </div>
        </div>
        """)

        # Connect the processing function
        process_btn.click(
            fn=process_chaos,
            inputs=[file_input, text_input, api_key, model_choice],
            outputs=[
                status_output,
                text_preview,
                summary_output,
                tasks_output,
                deadlines_output,
                entities_output,
                complete_output,
                text_input  # This will clear the text input when file is processed
            ],
            show_progress=True
        )

        # Add file change event to clear text when file is uploaded
        def clear_text_on_file_upload(file):
            if file is not None:
                return gr.update(value="")
            return gr.update()

        file_input.change(
            fn=clear_text_on_file_upload,
            inputs=[file_input],
            outputs=[text_input]
        )

        # Example interactions
        gr.Examples(
            examples=[
                [None, "Meeting with Sarah tomorrow at 3pm to discuss Q4 budget. Need to prepare financial reports and contact John about vendor contracts. Deadline for proposal is Friday. Also remember to call Mom.", "", "anthropic/claude-3.5-sonnet"],
                [None, "Project kickoff next Monday. Team: Alice (PM), Bob (Dev), Carol (Design). Deliverables: wireframes by Wed, prototype by next Friday. Budget approved: $50K. Client meeting scheduled for end of month.", "", "anthropic/claude-3.5-sonnet"],
            ],
            inputs=[file_input, text_input, api_key, model_choice],
        )

    return app

# Main execution
def main():
    """Main function to run the app"""

    print("üöÄ Starting AI Life Admin - Upload Your Chaos")
    print("üé® Loading beautiful Gradio interface...")

    # Create and launch the app
    app = create_app()

    # Launch with public sharing for Colab
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True,  # Creates public URL for Colab
        show_api=False,
        show_error=True,
        debug=False,
        auth=None,  # Add authentication in production
        inbrowser=True
    )

if __name__ == "__main__":
    main()